<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <!-- Favicon -->
    <link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96" />
    <link rel="icon" type="image/svg+xml" href="/favicon.svg" />
    <link rel="shortcut icon" href="/favicon.ico" />
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
    <meta name="apple-mobile-web-app-title" content="Kaomoji" />
    <link rel="manifest" href="/site.webmanifest" />

    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <!-- Basic Meta Tags -->
    <title>LLM Parameter Visualization – Explore Token Probability & Sampling Effects</title>
    <meta name="description" content="Interactively visualize how temperature, top-k, and nucleus sampling affect token probabilities in LLM predictions. Understand and fine-tune model randomness with ease."/>
    <meta name="keywords" content="LLM visualization, token probability, AI model parameters, temperature tuning, top-k sampling, nucleus sampling, language model, AI prediction analysis" />
    
    <!-- Open Graph Meta Tags (for social media sharing) -->
    <meta property="og:title" content="LLM Parameter Visualization – Explore Token Probability & Sampling Effects" />
    <meta property="og:description" content="Interactively visualize how temperature, top-k, and nucleus sampling affect token probabilities in LLM predictions. Understand and fine-tune model randomness with ease." />
    <meta property="og:image" content="https://res.cloudinary.com/moyadev/image/upload/v1743499217/maia/llm-temp_wwtth9.webp" />
    <meta property="og:url" content="https://llm-temp.vercel.app" />
    <meta property="og:type" content="website" />
    
    <!-- Twitter Card Meta Tags -->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="LLM Parameter Visualization – Explore Token Probability & Sampling Effects" />
    <meta name="twitter:description" content="Interactively visualize how temperature, top-k, and nucleus sampling affect token probabilities in LLM predictions. Understand and fine-tune model randomness with ease." />
    <meta name="twitter:image" content="https://res.cloudinary.com/moyadev/image/upload/v1743499217/maia/llm-temp_wwtth9.webp" />
  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.tsx"></script>
  </body>
</html>